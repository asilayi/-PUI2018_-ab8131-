{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# Skeleton of Assignment 4:\n",
    "    test if the distribution of \n",
    "    \n",
    "    1) trip duration of bikers that ride during the day vs night\n",
    "    \n",
    "    2) age of bikers for trips originating in Manhattan and in Brooklyn (extra credit)\n",
    "    \n",
    "    are different. Use 3 tests: KS, Pearson's, Spearman's. \n",
    "    \n",
    "    Use the scipy.stats functions scipy.stats.ks_2samp, scipy.stats.pearsonr, scipy.stats.spearmanr. \n",
    "    \n",
    "    For the KS do the test with the entire dataset and with a subset 200 times smaller\n",
    "    \n",
    "    Choose a single significant threshold for the whole exercise. \n",
    "    \n",
    "    For each test phrase the Null Hypothesis in words.\n",
    "    \n",
    "    Describe the return of the scipy function you use in each case.\n",
    "    \n",
    "    State the result in terms of rejection of the Null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-05T16:48:06.390950",
     "start_time": "2017-10-05T16:48:04.815178"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n",
      "/nfshome/ab8131/PUIdata\n"
     ]
    }
   ],
   "source": [
    "# my usual imports and setups\n",
    "import pylab as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#imports downloader\n",
    "#from getCitiBikeCSV import getCitiBikeCSV\n",
    "\n",
    "%pylab inline\n",
    "\n",
    "import os\n",
    "#this makes my plots pretty! but it is totally not mandatory to do it\n",
    "import json\n",
    "#s = json.load( open(os.getenv ('PUI2016')+\"/fbb_matplotlibrc.json\") )\n",
    "#pl.rcParams.update(s)\n",
    "if os.getenv ('PUI2016') is None:\n",
    "    print (\"Must set env variable PUI2016\")\n",
    "if os.getenv ('PUIDATA') is None:\n",
    "    print (\"Must set env variable PUI2016\")\n",
    "print(os.getenv(\"PUIDATA\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# Read in data\n",
    "I am reading in data from January 2015 with the function that I created getCitiBikeCSV. You are requested to use 2 months at least. It would be a good idea to use data from a colder and a warmer months, since there are more riders in the warm weather and ridership patterns may change with weather, temperature, etc. You should use data from multiple months, joining multiple datasets (thus addressing some systematic errors as well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCitiBikeCSV(datestring):\n",
    "    print (\"Downloading\", datestring)\n",
    "    ### First I will heck that it is not already there\n",
    "    if not os.path.isfile(os.getenv(\"PUIDATA\") + \"/\" + datestring + \"-citibike-tripdata.csv\"):\n",
    "        if os.path.isfile(datestring + \"-citibike-tripdata.csv\"):\n",
    "            # if in the current dir just move it\n",
    "            if os.system(\"mv \" + datestring + \"-citibike-tripdata.csv \" + os.getenv(\"PUIDATA\")):\n",
    "                print (\"Error moving file!, Please check!\")\n",
    "        #otherwise start looking for the zip file\n",
    "        else:\n",
    "            if not os.path.isfile(os.getenv(\"PUIDATA\") + \"/\" + datestring + \"-citibike-tripdata.zip\"):\n",
    "                if not os.path.isfile(datestring + \"-citibike-tripdata.zip\"):\n",
    "                    os.system(\"curl -O https://s3.amazonaws.com/tripdata/\" + datestring + \"-citibike-tripdata.zip\")\n",
    "                ###  To move it I use the os.system() functions to run bash commands with arguments\n",
    "                os.system(\"mv \" + datestring + \"-citibike-tripdata.zip \" + os.getenv(\"PUIDATA\"))\n",
    "            ### unzip the csv \n",
    "            os.system(\"unzip \" + os.getenv(\"PUIDATA\") + \"/\" + datestring + \"-citibike-tripdata.zip\")\n",
    "            ## NOTE: old csv citibike data had a different name structure. \n",
    "            if '2014' in datestring:\n",
    "                os.system(\"mv \" + datestring[:4] + '-' +  datestring[4:] + \n",
    "                          \"\\ -\\ Citi\\ Bike\\ trip\\ data.csv \" + datestring + \"-citibike-tripdata.csv\")\n",
    "            os.system(\"mv \" + datestring + \"-citibike-tripdata.csv \" + os.getenv(\"PUIDATA\"))\n",
    "    ### One final check:\n",
    "    if not os.path.isfile(os.getenv(\"PUIDATA\") + \"/\" + datestring + \"-citibike-tripdata.csv\"):\n",
    "        print (\"WARNING!!! something is wrong: the file is not there!\")\n",
    "\n",
    "    else:\n",
    "        print (\"file in place, you can continue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-05T16:48:09.386484",
     "start_time": "2017-10-05T16:48:06.821336"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 201502\n",
      "file in place, you can continue\n"
     ]
    }
   ],
   "source": [
    "datestring = '201502'\n",
    "getCitiBikeCSV(datestring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-05T16:48:11.528975",
     "start_time": "2017-10-05T16:48:10.267002"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tripduration</th>\n",
       "      <th>starttime</th>\n",
       "      <th>stoptime</th>\n",
       "      <th>start station id</th>\n",
       "      <th>start station name</th>\n",
       "      <th>start station latitude</th>\n",
       "      <th>start station longitude</th>\n",
       "      <th>end station id</th>\n",
       "      <th>end station name</th>\n",
       "      <th>end station latitude</th>\n",
       "      <th>end station longitude</th>\n",
       "      <th>bikeid</th>\n",
       "      <th>usertype</th>\n",
       "      <th>birth year</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>801</td>\n",
       "      <td>2/1/2015 0:00</td>\n",
       "      <td>2/1/2015 0:14</td>\n",
       "      <td>521</td>\n",
       "      <td>8 Ave &amp; W 31 St</td>\n",
       "      <td>40.750450</td>\n",
       "      <td>-73.994811</td>\n",
       "      <td>423</td>\n",
       "      <td>W 54 St &amp; 9 Ave</td>\n",
       "      <td>40.765849</td>\n",
       "      <td>-73.986905</td>\n",
       "      <td>17131</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1978.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>379</td>\n",
       "      <td>2/1/2015 0:00</td>\n",
       "      <td>2/1/2015 0:07</td>\n",
       "      <td>497</td>\n",
       "      <td>E 17 St &amp; Broadway</td>\n",
       "      <td>40.737050</td>\n",
       "      <td>-73.990093</td>\n",
       "      <td>504</td>\n",
       "      <td>1 Ave &amp; E 15 St</td>\n",
       "      <td>40.732219</td>\n",
       "      <td>-73.981656</td>\n",
       "      <td>21289</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2474</td>\n",
       "      <td>2/1/2015 0:01</td>\n",
       "      <td>2/1/2015 0:42</td>\n",
       "      <td>281</td>\n",
       "      <td>Grand Army Plaza &amp; Central Park S</td>\n",
       "      <td>40.764397</td>\n",
       "      <td>-73.973715</td>\n",
       "      <td>127</td>\n",
       "      <td>Barrow St &amp; Hudson St</td>\n",
       "      <td>40.731724</td>\n",
       "      <td>-74.006744</td>\n",
       "      <td>18903</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1969.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>818</td>\n",
       "      <td>2/1/2015 0:01</td>\n",
       "      <td>2/1/2015 0:15</td>\n",
       "      <td>2004</td>\n",
       "      <td>6 Ave &amp; Broome St</td>\n",
       "      <td>40.724399</td>\n",
       "      <td>-74.004704</td>\n",
       "      <td>505</td>\n",
       "      <td>6 Ave &amp; W 33 St</td>\n",
       "      <td>40.749013</td>\n",
       "      <td>-73.988484</td>\n",
       "      <td>21044</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>544</td>\n",
       "      <td>2/1/2015 0:01</td>\n",
       "      <td>2/1/2015 0:10</td>\n",
       "      <td>323</td>\n",
       "      <td>Lawrence St &amp; Willoughby St</td>\n",
       "      <td>40.692362</td>\n",
       "      <td>-73.986317</td>\n",
       "      <td>83</td>\n",
       "      <td>Atlantic Ave &amp; Fort Greene Pl</td>\n",
       "      <td>40.683826</td>\n",
       "      <td>-73.976323</td>\n",
       "      <td>19868</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>1957.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tripduration      starttime       stoptime  start station id  \\\n",
       "0           801  2/1/2015 0:00  2/1/2015 0:14               521   \n",
       "1           379  2/1/2015 0:00  2/1/2015 0:07               497   \n",
       "2          2474  2/1/2015 0:01  2/1/2015 0:42               281   \n",
       "3           818  2/1/2015 0:01  2/1/2015 0:15              2004   \n",
       "4           544  2/1/2015 0:01  2/1/2015 0:10               323   \n",
       "\n",
       "                  start station name  start station latitude  \\\n",
       "0                    8 Ave & W 31 St               40.750450   \n",
       "1                 E 17 St & Broadway               40.737050   \n",
       "2  Grand Army Plaza & Central Park S               40.764397   \n",
       "3                  6 Ave & Broome St               40.724399   \n",
       "4        Lawrence St & Willoughby St               40.692362   \n",
       "\n",
       "   start station longitude  end station id               end station name  \\\n",
       "0               -73.994811             423                W 54 St & 9 Ave   \n",
       "1               -73.990093             504                1 Ave & E 15 St   \n",
       "2               -73.973715             127          Barrow St & Hudson St   \n",
       "3               -74.004704             505                6 Ave & W 33 St   \n",
       "4               -73.986317              83  Atlantic Ave & Fort Greene Pl   \n",
       "\n",
       "   end station latitude  end station longitude  bikeid    usertype  \\\n",
       "0             40.765849             -73.986905   17131  Subscriber   \n",
       "1             40.732219             -73.981656   21289  Subscriber   \n",
       "2             40.731724             -74.006744   18903  Subscriber   \n",
       "3             40.749013             -73.988484   21044  Subscriber   \n",
       "4             40.683826             -73.976323   19868  Subscriber   \n",
       "\n",
       "   birth year  gender  \n",
       "0      1978.0       2  \n",
       "1      1993.0       1  \n",
       "2      1969.0       2  \n",
       "3      1985.0       2  \n",
       "4      1957.0       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(os.getenv(\"PUIDATA\") + \"/\" + datestring + '-citibike-tripdata.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-05T16:51:52.008367",
     "start_time": "2017-10-05T16:48:18.977948"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# df is the dataframe where the content of the csv file is stored\n",
    "df['date'] = pd.to_datetime(df['starttime'])\n",
    "# note that with dataframes I can refer to variables as dictionary keys, \n",
    "# i.e. df['starttime'] or as attributes: df.starttime. \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# SPLIT BY CATEGORY\n",
    "\n",
    "I am splitting data by trips at day and at night:\n",
    "\n",
    "**H0: there is no statistical difference between tripdurations at day and at night**\n",
    "$$ \\alpha = 0.05 $$\n",
    "\n",
    "To simply the question, here I assume that \n",
    "\n",
    "daytime: 6am to 6pm\n",
    "\n",
    "nighttime: 6pm to 6am."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['starttime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-05T16:51:52.357332",
     "start_time": "2017-10-05T16:51:52.017199"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#df is the dataframe where the content of the csv file is stored\n",
    "#df_day = df[['start station id', 'tripduration']][(df['date'].dt.hour >= 6) & (df['date'].dt.hour < 18)]\n",
    "#df_night = df[['start station id', 'tripduration']][(df['date'].dt.hour >=18) | (df['date'].dt.hour < 6)]\n",
    "df_day = df[(df['date'].dt.hour >= 6) & (df['date'].dt.hour < 18)]\n",
    "df_night = df[(df['date'].dt.hour >=18) | (df['date'].dt.hour < 6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#dropping some data I no longer need\n",
    "#... your code here...\n",
    "df_day = df_day[['tripduration', 'start station id']]\n",
    "df_night = df_night[['tripduration', 'start station id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_day.describe()\n",
    "#df_night.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_night.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-05T16:55:05.649685",
     "start_time": "2017-10-05T16:55:05.635796"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# dropping NaN values\n",
    "df_day.dropna(inplace = True)\n",
    "df_night.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "lets split age in 10 year bins. the dataset is very large, so i could be split in smaller bins, but I will chose 10 years in the interest of time. \n",
    "the bin size choice should be a balance between properly sample the age space, have enough counts in each bin that the statistical noise is not significant (remember that is > sqrt(N)!) and the computational requirement to computatinal facilities ratio. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "the next several steps are needed if you want to code up the KS test from scratch. that is for extra credit, so if you do not want to do it you may not need to plot split the distribution in bins and create the cumulative HOWEVER it is a great idea to do it anyways to explore your data viaually! remember Ascombe's quartet!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-05T16:55:21.602238",
     "start_time": "2017-10-05T16:55:20.487384"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# plotting histogramswith pandas is a bitdifferent than with pylab\n",
    "# this is a VERY USEFUL syntaxfor you to knonw!\n",
    "bins = np.arange(60,3000,100)\n",
    "axD = df_day.tripduration.groupby(pd.cut(df_day.tripduration, bins)).agg([count_nonzero]).plot(kind='bar', \n",
    "                                                                legend=False)\n",
    "axD.set_title(\"tripduration at day time\")\n",
    "axN = df_night.tripduration.groupby(pd.cut(df_night.tripduration, bins)).agg([count_nonzero]).plot(kind='bar',\n",
    "                                                                legend=False)\n",
    "axN.set_title(\"tripduration at night time\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "**Figure 1: histogrammed distribution of riders' tripduration by datetime **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "this is how the cumulative distributions look like.  Notice that i am normalizing them! if i want to reat an observed distribution like a probablility distribution i have to normalize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#print df.ageS, df.ageS.cumsum()\n",
    "\n",
    "csD=df_day.tripduration.groupby(pd.cut(df_day.tripduration, bins)).agg([count_nonzero]).cumsum()\n",
    "\n",
    "csN=df_night.tripduration.groupby(pd.cut(df_night.tripduration, bins)).agg([count_nonzero]).cumsum()\n",
    "\n",
    "print (np.abs(csD / csD.max()-csN / csN.max()))\n",
    "\n",
    "pl.plot(bins[:-1] + 5, csD / csD.max(), label = \"Day\")\n",
    "pl.plot(bins[:-1] + 5, csN / csN.max(), label = \"Night\")\n",
    "pl.plot(bins[:-1] + 5, np.sqrt(csN / csN.max() - csD / csD.max())**2, 'k-',\n",
    "        label = \"difference\")\n",
    "pl.xlabel(\"Tripduration\")\n",
    "pl.ylabel(\"Normalized Cumulative Number\")\n",
    "pl.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "** Figure 2: the cumulative distribution of CitiBike riders' trip duration by datetime** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "They look similar! But the difference gets to 10%. If I wanted to code the KS test by hand I woud have everything I need: the normalized cumulative distributions can be subtracted from each other and the max distance can calculated. \n",
    "\n",
    "Notice that there may be NaN values you are gonna have to deal with! \n",
    "You can do that for example with a Boolean statementsuch as  df.ageF[~np.isnan(df.ageF)] or you can use numpy functions that deal with Nan values: nansum, nanmean, nanstd..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "lets run the scipy KS test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-05T16:58:02.949986",
     "start_time": "2017-10-05T16:58:02.443596"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "#remember that your imports should all be at the top. I leave it here to hightlight that this package is needed at this point of the workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# KS tests to compare 2 samples\n",
    "\n",
    "http://docs.scipy.org/doc/scipy-0.15.1/reference/generated/scipy.stats.ks_2samp.html\n",
    "\n",
    "the KS test in scipy returns the p-value BUT make sure you understand what the NULL is! read the documentation carefully! what is the null hypothesis that you can/cannot reject?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-05T16:58:13.968035",
     "start_time": "2017-10-05T16:58:13.899033"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "ks = scipy.stats.ks_2samp(df_day.tripduration, df_night.tripduration)\n",
    "print (ks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "**  FILL IN THE CELL BELOW!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-05T16:58:24.751556",
     "start_time": "2017-10-05T16:58:24.747653"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "#### Null hypothesis: the tripduration of trips on day time is the same with the tripduration of trips on night time, under significance level 0.05.\n",
    "According to the KS test, we found that the \n",
    "\n",
    "KS test statistics = 0.0122\n",
    "\n",
    "p-value = 1.20e-05 < 0.05\n",
    "\n",
    "Thus we reject the null hypothesis under significance level 0.05 and conclude that the tripduration of trips on day time is not the same with the tripduration of trips on night time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "The scipy.stats KS test already tells me the significance and the p-value. \n",
    "\n",
    "The next few cells are here just to show you how you would obtain the same result by hand, but they are **not required**. \n",
    "\n",
    "Remember: the Null hypothesis is rejected if \n",
    "\n",
    "$D_KS(n1,n2) > c(\\alpha) \\sqrt{\\frac{(n1 + n2)}{n1n2}}$\n",
    "\n",
    "(see class notes) where $c(\\alpha$) is the inverse of the KS distribution, and you do not have to know how to get that cause there are tables that list critical values!! \n",
    "\n",
    "http://www.real-statistics.com/tests-normality-and-symmetry/statistical-tests-normality-symmetry/kolmogorov-smirnov-test/kolmogorov-distribution/\n",
    "\n",
    "But also this result depends in your choice of binning through, and thustheresultyou get by hand may not be exactly the same as the one the KS returns. Either way: this is how you would calculate the KS statistics by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-05T16:58:33.858841",
     "start_time": "2017-10-05T16:58:33.850240"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#here is the critical values tablel. Have you chosen your significance level yet?? you should do it first thing!\n",
    "from IPython.display import Image\n",
    "Image(filename=\"../plotsforclasses/ks2sample_table.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redo KS tests with the reduced dataset (200 times smaller)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-05T16:58:45.489436",
     "start_time": "2017-10-05T16:58:45.483526"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "## your words here!...\n",
    "## this cell is for you to redo the test with reducted dataset \n",
    "## and tell me what the scipy ks test returned and what it means in terms of NULL HYPOTHESIS\n",
    "df_dayks = df_day.sample(frac = .05, random_state = 200)\n",
    "df_nightks = df_night.sample(frac = .05, random_state = 200)\n",
    "ks2 = scipy.stats.ks_2samp(df_dayks.tripduration, df_nightks.tripduration)\n",
    "print (ks2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Null hypothesis: the tripduration of trips on day time is the same with the tripduration of trips on night time, under significance level 0.05.\n",
    "According to the KS test, we found that the \n",
    "\n",
    "KS test statistics = 0.025\n",
    "\n",
    "p-value = 0.1548 > 0.05\n",
    "\n",
    "Thus we fail to reject the null hypothesis under significance level 0.05 and conclude that the tripduration of trips on day time is the same with the tripduration of trips on night time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# Now retest using a test for correlation. \n",
    "\n",
    "That will answer a slightly different question though - formulate the NULL appropriately. The tests for correlations (generally) requires the variable to be paired, so that I can tell if x changes does y change similarly. But the datasets are of different size! You will need to reduce them to the same size. You can do that by subsampling of the data: take only 1 ride every of 200, which you can achieve \"slicing and broadcasting\" the array or using one of the python function (built in python numpy.random.choice() functions for example: Docstring:\n",
    "choice(a, size=None, replace=True, p=None)\n",
    "\n",
    "Generates a random sample from a given 1-D array\n",
    "\n",
    "        .. versionadded:: 1.7.0\n",
    "\n",
    "Parameters\n",
    "...\n",
    "\n",
    "But make sure you understand how to use it! there is an option \"replace\" which you should think about."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# Pearson's  test for correlation\n",
    "\n",
    "** notice that the Pearson's is a pairwise test: the samples need to be **\n",
    " a. the same size\n",
    " b. sorted! (how??)\n",
    "    \n",
    "http://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.pearsonr.html#scipy.stats.pearsonr\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dayPr = np.random.choice(df_day.tripduration, 10000)\n",
    "df_nightPr = np.random.choice(df_night.tripduration, 10000)\n",
    "df_dayPr.sort()\n",
    "df_nightPr.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-05T17:05:04.485128",
     "start_time": "2017-10-05T17:05:04.480928"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "pearson = scipy.stats.pearsonr(df_dayPr, df_nightPr)\n",
    "print(pearson)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Null hypothesis: the tripduration of trips on day time is not correlated with the tripduration of trips on night time, under significance level 0.05.\n",
    "According to the Pearson's test, we found that the \n",
    "\n",
    "Pearson test statistics = 0.962\n",
    "\n",
    "p-value = 0 < 0.05\n",
    "\n",
    "Thus we reject the null hypothesis under significance level 0.05 and conclude that the tripduration of trips on day time is correlated with the tripduration of trips on night time, under significance level 0.05."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# Spearman's  test for correlation\n",
    "\n",
    "http://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.spearmanr.html#scipy.stats.spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-05T17:05:09.530148",
     "start_time": "2017-10-05T17:05:09.525214"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here!\n",
    "# wrangle the data as needed\n",
    "# please perform the Spearman's test and tell me what you find in terms of NULL hypothesis\n",
    "spearman = scipy.stats.spearmanr(df_dayPr, df_nightPr)\n",
    "print(spearman)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "#### Null hypothesis: the tripduration of trips on day time is not correlated with the tripduration of trips on night time, under significance level 0.05.\n",
    "According to the Spearman's test, we found that the \n",
    "\n",
    "Spearman test statistics = 0.999\n",
    "\n",
    "p-value = 0 < 0.05\n",
    "\n",
    "Thus we reject the null hypothesis under significance level 0.05 and conclude that the tripduration of trips on day time is correlated with the tripduration of trips on night time, under significance level 0.05."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# Extra Credit\n",
    "## age of bikers for trips originating in Manhattan and in Brooklyn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "PUI2016_Python3",
   "language": "python",
   "name": "pui2016_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "135px",
    "width": "251px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
